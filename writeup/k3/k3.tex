\documentclass[titlepage]{article}
\usepackage{listings}
\usepackage{hyperref}

\lstset{basicstyle=\footnotesize\ttfamily,breaklines=true}

\begin{document}
\title{Kernel 3}
\author{Justin McGirr (\#20413625), Peter Raboud (\#20437716)}
\maketitle

\section{Instructions}
\input{"../k1/README.tex"}

\section{Design Decisions}
\subsection{Await Interface}
The implementation of await was something that we debated for quite some time,
because we were given multiple choices in implementation, and because there is
a lot of literature on the different approaches to device driver isolation.
Given that we are writing a microkernel, we want, for various reasons, the
kernel itself to be as small as possible. This allows isolation of failures,
easy prioritization of tasks, and more. However, given that we are, in our toy
kernel, only writing device drivers for a \emph{very} small number of
peripherals, creating all the primatives to allow safe and race-free access
to peripherals from driver tasks seemed like it would likely end up being
bigger and more complex than just implementing a HAL in the kernel. For
example, if the user task is responsible for asking the device to deassert
its interrupt, then you need to make sure that you don't enable interrupts
when switching back to the user task, or else the user task will just get
immediately interrupted again, leading to an infinite loop. However, if you
don't enable interrupts, then you can't preempt the user task, losing a
significant advantage of implementing that portion of the device communication
in userland. Thus, at least for this iteration of the kernel, we have chosen
to have the kernel read the data from the device, deassert the interrupt,
and return the relevant data back to the userland \texttt{await()} call.

\subsection{Await Data Structures}
For keeping track of tasks that are blocked awaiting external events, we used
a array of queues, one queue for each different possible event. This allows
constant-time removal and addition of tasks from waiting queues. The latter
is particularilly important, as tasks are currently dequed immediately in the
interrupt handler, where speed is particularilly important, because it can
directly impact the worst-case latency of a response. Had a linear scan been
used instead, this could  yield quite bad latency if many tasks were stacked
up waiting for interrupts, particularilly if many were stacked up at the same
time.

We currently deque all of the waiting tasks when an event occurs. This could
cause some performance problems if many tasks are queued up at once, because
a single interrupt would have to deque all of them. However, this is not
currently a problem, because we only ever have a single task at a time
awaiting an event.

\subsection{Clockserver}
As part of this assignment, we implemented a clock server as a user task, which
allows other user tasks to request the current time, schedule themselves to run
at some point at least $n$ ticks in the future, or schedule themselves to
run at some absolute tick $m$ in the future. I assume this will be very useful
when we start having trains going aronud the track, and we will start having
tasks which care about real-world values like time and distance.

To keep track of tasks which requested future wakeup, we chose to use a
min-heap. This allows $lg(n)$ time insertion and removal of elements, with
constant-time querying of the smallest element. The latter is the most
important property, assuming the data structure isn't crazy stupid in other
ways, because we have to check the top element of this queue against the
number of ticks which have passed, \emph{every single tick}. An additional
reason for the choice of this data structure was that we coincidentally
happened to have one lying around from k1, because we thought we might end up
using it for our priority queues (although we ended up going with an
alternative data structure for that assignment).

\subsection{Interrupt-Triggered Context Switch}
As part of this assignment, we had to figure out and write a context switching
routine to be run when an interrupt was triggered. We chose to implement this as
a context switch into the kernel, where the interface to the kernel just looks
like an svc call, but with a \texttt{SYSCALL\_IRQ} syscall number, where the kernel then
handles the interrupt just as it would a regular syscall. We considered having
an extra psuedo-task to handle interrupts, with it's own stack, which would
automatically get "scheduled" whenever an interrupt was triggered, but decided
that the additional complexity would not be worth the benifits, and additionally
such a design would waste some space- the IRQ stack would only be used when
IRQs are triggered, and is unlikely to hold much of anything useful the rest
of the time.

The actual context switching function is different depending on whether the
interrupt originated from an svc call or a irq, although almost all of the
source code is shared through the use of assembly macros. Although we considered
trying to fit both context switches into a single block of code through the use
of conditional execution, it seemed like it would complicate things
considerably, not least of which because you would have to find a register to
store that state in. As the context switch is only slightly more than ten
instructions, we opted just to implement the conditions at the assembler level.

% Things we should probably talk about (not a complete list, just a brain dump
% of some things I think we should include)
% - how we queue tasks awaiting events
% - how we chose our await_event() signature
% - the clockserver implementation (choice of min heap to maintain the list of waiting tasks)
% - how the context switch works in the new world order (and why we chose to
%   have 2 separate context switches)

\section{Questions}

The output produced by running the kernel is reproduced below:

\begin{verbatim}
Boot......IO...
tid: 4, interval: 10, round: 0
tid: 4, interval: 10, round: 1
tid: 5, interval: 23, round: 0
tid: 4, interval: 10, round: 2
tid: 6, interval: 33, round: 0
tid: 4, interval: 10, round: 3
tid: 5, interval: 23, round: 1
tid: 4, interval: 10, round: 4
tid: 4, interval: 10, round: 5
tid: 6, interval: 33, round: 1
tid: 5, interval: 23, round: 2
tid: 4, interval: 10, round: 6
tid: 7, interval: 71, round: 0
tid: 4, interval: 10, round: 7
tid: 4, interval: 10, round: 8
tid: 5, interval: 23, round: 3
tid: 6, interval: 33, round: 2
tid: 4, interval: 10, round: 9
tid: 4, interval: 10, round: 10
tid: 5, interval: 23, round: 4
tid: 4, interval: 10, round: 11
tid: 4, interval: 10, round: 12
tid: 6, interval: 33, round: 3
tid: 5, interval: 23, round: 5
tid: 4, interval: 10, round: 13
tid: 7, interval: 71, round: 1
tid: 4, interval: 10, round: 14
tid: 4, interval: 10, round: 15
tid: 5, interval: 23, round: 6
tid: 6, interval: 33, round: 4
tid: 4, interval: 10, round: 16
tid: 4, interval: 10, round: 17
tid: 5, interval: 23, round: 7
tid: 4, interval: 10, round: 18
tid: 6, interval: 33, round: 5
tid: 4, interval: 10, round: 19
tid: 5, interval: 23, round: 8
tid: 7, interval: 71, round: 2
Exiting kernel...
Task 0 ran for 1981447 us
Task 1 ran for 338 us
Task 2 ran for 310 us
Task 3 ran for 1205 us
Task 4 ran for 3266 us
Task 5 ran for 1379 us
Task 6 ran for 928 us
Task 7 ran for 438 us
Task 8 ran for 528 us
Kernel ran for 146629 us
Ran for 2136468 us total
\end{verbatim}

The first line is output produced as the kernel loads up, to provide feedback in the case that it breaks,
and is not significant here.

The following lines (until \texttt{Exiting kernel...}) are printed by the client tasks, after every delay.
Because each message is printed out after a delay, output is not produced immediately by each task.
This causes the tasks with the smallest delays to print out several times tasks with longer delays wake up.

At the moment, the tasks print in a stable / predictable order.
This is because the tasks have different delay periods which aren't multiples of each other.
If the resume and wait process was instantaenous, this would mean that the tasks would wake up at $d, 2d, 3d, \ldots$,
and since the GCD of any two $d$'s of the tasks is bigger than the amount of time the program runs, these
numbers never collide.
Since our resume and wait process never takes more than a single clock tick (10ms), it is sufficiently close to instantaenous
that clock ticks aren't dropped by the client tasks.
(i.e.: a clock is supposed to be resumed at time $t$, but goes back to sleep at $t + \delta$.
When it requests \texttt{delay(d)}, it will be woken back up at $t + \delta + d$, when it would ideally
be woken up at $t + d$.)
Therefore, because our kernel and user tasks are sufficiently fast (at least for now), and because
none of the wakeup periods align with each other, there is a predictable order for waking up the tasks again.

\section{Source Code}
The source code is hosted on git, at \url{git.uwaterloo.ca/pgraboud/cs452-kernel}.
The version we wish to submit is on the \texttt{k3} branch, specifically
the commit:
\input{|"git rev-parse HEAD | ./../verbatim"}
We are submitting the following files:
\input{|"cat ../file-list | ./../verbatim"}
\input{|"./../file-list | ./../verbatim"}

\end{document}
