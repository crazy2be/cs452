\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{algpseudocode}
\usepackage{hyperref}

\title{Trains Control 2}
\author{Justin McGirr (\#20413625), Peter Raboud (\#20437716)}
\date{\today}

\begin{document}

\maketitle

\section{Instructions}
\input{"README.tex"}

\section{Design decisions}
% overview of stuff we might like to talk about
% X we've already discussed acceleration before - we may want to make reference to the fact that we've discussed the fundamentals,
%   and then talk about only the new stuff (actually using the model in our code, for the sensor attribution & and position estimation after
%   stopping). we should discuss that this is only a model for stopping, and we never generalized it to acceleration,
%   although we probably could have
% - overview of the routefinding - discuss a* (advantages over djikstra's), limitations of LRA*, difficulties with multi-agent pathfinding
% X the POI system which drives the conductors
% - track reservation
% X sensor attribution
% - the train simulator
% X delay_async & send_async

% - our instructions should explicitly describe the parts of the system that weren't completed
\subsection{Routefinding}
We spent a significant amonut of time researching and experimenting with
different possible algorithms for routefinding. For the single agent case,
and for a map as small as our train track, routefinding is a fairly easily
solved problem- either Djikstras or A* is very fast, and always finds the
optimal solution. However, when multiple agents are involved, the solution
is much less clearcut. The most common algorithm used by our informal poll
of other students is referred to as LRA* in the literature, and looks
something like Algorithm \ref{alg:LRA*}.
\begin{algorithm}
\label{alg:LRA*}
\caption{LRA* Naive-A* Algorithm}
\begin{algorithmic}
\Loop
\State Whenever a train needs a route
\State route := single-agent-A*(train, reservation-table)
\State follow(train, route)
\EndLoop
\Function{follow}{train, route}
	\If{we cannot reserve at least stopping-distance ahead along route}
		\State stop the train
		\State find a new route
	\EndIf
	\State [...]
\EndFunction
\end{algorithmic}
\end{algorithm}

However, this psuedocode algorithm has many limitations, especially when many
agents are involved, or complex routes are to be navigated. It has no ability,
for example, to solve a fairly simple (although admittedly pathelogical) case
like the one in Figure \ref{fig:LRA*-unsolveable}. Although this exact
configuration does not exist on the real track, analagous configurations do,
such as near the exits.
\begin{figure}
\caption{Naive LRA* will never find a solution to this multi-agent routing
problem, as doing so requires some knowledge of other agents in the world,
which LRA* does not posess.}
\label{fig:LRA*-unsolveable}
\includegraphics[width=\linewidth]{LRA*-unsolveable.png}
\end{figure}

Even in much less pathelogical cases, LRA* tends to chose suboptimal paths,
and will not realize that a path is not going to work until it has been at
least partially executed. For example, imagine a track like
Figure \ref{fig:LRA*-suboptimal}. In this configuration, the most optimal
paths for train 1 and train 2 overlap in opposing directions. Despite the
fact that it is clearly impossible to actually follow this route for both
trains, the LRA* algorithm will happily try, until it is too late, and one
(or, if you're particularly unlucky, potentially both) of the trains will
reverse and take the opposite path. Of course, at this point, is has already
travelled most of the way to it's destination- distance which turned out to
be in the opposite direction of the goal. A smarter algorithm would realize
eventual collision was inevitable, and reverse one of the trains to begin with.
\begin{figure}
\caption{LRA* will not realize a collision is inevitable until it is imminent.
A smarter algorithm could look ahead, and would never bother exploring an
impossible path.}
\label{fig:LRA*-suboptimal}
\includegraphics[width=\linewidth]{LRA*-suboptimal.png}
\end{figure}

In an attempt to avoid these pitfals, we spent a significant amount of time
researching and experimenting with different approaches, including the "simple"
extension to A* which just searches the combined search space of all agents
together, rather than each agent individually. It's described
in\footnote{\url{http://rbr.cs.umass.edu/papers/SCZuai05.pdf}}, although we
implemented it based on the fairly loose description
in\footnote{\url{https://www.aaai.org/ocs/index.php/WS/AAAIW12/paper/viewFile/5233/5640}}
and\footnote{\url{http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Applications_files/coop-path-AIIDE.pdf}}. This MAA* algorithm has none of the pitfals of LRA*, and is
gaurenteed both to find a solution if one exists, and to find the globally
optimal solution. The trade-off, of course, is twofold.
\begin{enumerate}
\item You need a perfect model of the trains in order to have the algorithm
	properly plan the optimal path, (or, at least, a model with a sufficiently
	small error that you can pad out projection errors enough that you can
	ignore them, without causing excessive track reservations due to your
	padding).
\item Your search space grows exponentially with the number of agents, since
	each additional agent increases the number of possible next states for
	any given state by a linear amount, increasing the total search space
	exponentially. For the single-agent case, your runtime is $O(d^b)$,
	where d is the depth of the path, and b is the branching factor
	(4 in our case, with options: straight,curved, reverse straight,
	reverse curved). For the multi-agent case with $n$ agents, this becomes
	$O((d*n)^{b*n})$,
	since at each level, you can choose any one of the agents to make any one
	of it's possible moves. The path through the search space is also longer,
	because each agent having a path of length d corresponds to a total search
	space path of $d*n$. Based on some basic Fermi calculations, we figured
	this would be computationally feasible for 2 agents, potentially possible
	for 3 agents, would require a server farm for 4 agents, and became currently
	completely infeasible after that.
\end{enumerate}

Of course, there are many compromises between the approaches. HCA*, for
example, does A* for each agent individually, but when calculating the possible
paths each agent can take, it takes into account the time-dependant reservations
of the other agents who ran before it. This approach is \emph{usually} able to
find a satisfactory solution, runs much faster than MAA*, and was also more
clearly adaptable to realtime use when conditions on the track diverged from
what our model predicted. The results in the paper
\footnote{\url{http://www0.cs.ucl.ac.uk/staff/D.Silver/web/Applications_files/coop-path-AIIDE.pdf}}
looked promising in terms of scalability and runtime, particularly in it's
(relatively) low initial computation time (we estimated $<100ms$ for our problem
set), and very fast recomputation time (we estimated $<20ms$).

However, after all of this promising exploration, we hit a wall. In attempting
to find solutions to these problems, one of us spent something
close to a week looking at papers and researching different possible solutions,
anticipating that the routefinding was a significant portion of the challange
of making a good TC2 and trains project in general. This turned out to be a
mostly incorrect assumption, primarilly because other portions of the project
which we thought would be simple turned out to be surprisingly complex. The
conductor, for example, was expected to take something on the order of a few
hours, perhaps a day, but ended up taking closer to a week. Sensor attribution,
which we expected to take a few days at most, ended up taking a similarilly
large amount of time. In the end, even though we had really nice routefinding
(at least, for up to n=2 trains), our conductor didn't have the mid-route
reversing and short move support required to actually drive on the routes, so
we ended up just implementing the very simple LRA* algorithm.

\subsection{Sensor Attribution}
The interface created for sensor attribution was an \texttt{attribute} function called when a sensor goes from low to high.
It takes the sensor number, the time at which the sensor event happened, and a bundle of information about the track's current
recorded state, and it attempts to attribute the event to a train, or mark it as spurious.
The function attempts to find candidate trains which might have hit the sensor, based on the last
known positions of each of the trains, and the orientation of the turnouts.

We use depth-first search to traverse backwards from the sensor, in the direction that the train would have come from.
When we arrive at a sensor node which a train was previously at, we mark it as a candidate, and stop.
At a merge node, the train could have come from either side of the merge, so we continue down both
paths.

We are tolerant of at most one error from the track - either a single sensor which failed to read, or a single switch which
was in the wrong orientation.
If we arrive at a sensor without a train on it, we know that if the train is further down the search tree, it
would have needed to pass over the sensor without tripping it.
We prune off branches of the search tree that would need to pass through multiple sensors, so the search eventually terminates.
If we pass over a branch, if a train should have gone the other way of the branch, we tally an additional error.
Because the switches change orientation over time, we keep track of the history of the switches, compute the approximate
time that the train should have been at that switch, and find the position of the switch at that time.
Because the state of the switch is dependant on the position and speed of the train we think passed over it, we can't know
if the switch should have been in the other orientation at the time we traverse through the switch node.
We need to compute that after we have found a candidate for the train.
Therefore, we maintain a record of the switches through on the search, and the directions we expect them to be in,
and compute the number of errors from incorrect switches at the time we evaluate a train candidate.

We reject train candidates which require assuming more than one error.
If there are multiple candidates, we prefer the one with fewer assumed errors.
After that, we prefer the candidate which travelled the distance between their last known position and the switch hit
in the time closest to what we expect for how fast that train was going.

We have to do a bit of special work to attribute sensors to trains that have just reversed.
Normally, the last known position of a train is just the last sensor it hit.
However, this doesn't work when the train reverses.
When one or more of the trains has reversed recently, we calculate some possible positions for where
we might expect the train to stop.
We know how far the train would have travelled after the last sensor it hit, based on its velocity and stopping
distance.
We can therefore generate some candidate positions which account for possible switch or sensor failures.
When doing the depth-first search as described above, we can attribute a sensor hit to one of these
candidate positions in the same way that we would attribute a hit to the train travelling normally.
We do need to carry over errors assumed in calculating the candidate position to errors assumed in
the depth first search, in order to reject attributions which assume one error in the depth first search,
and one error when calculating the stopping position of the train.

There are some limitations of the approach that we took.
It's entirely possible for this function to attribute the same train to two sensors across multiple different calls.
We work around this issue by having a layer on top of the main sensor attribution function which rejects multiple
attribution, but this is not ideal.
In particular, it allows for two trains to both be candidates for the two sensor hits, and the same one to be picked for both.
The layer above sensor attribution rejects the second attribution, and treats the second hit as though it were spurious,
when in fact the better solution is to attribute one hit to each train.

Another issue is that the sensor attribution can be sensitive to inaccuracies in the estimated velocity of the train,
and doesn't tolerate poor estimates very well.
If the velocity estimate is off, it can make it look like the train went through many switches the wrong way, because
we miscalculate the time at which the train should be at the switch.
This can cause the sensor hit to be dismissed as spurious.

Moreover, when sensor attribution enters a bad state, it doesn't recover well.
When a sensor read is rejected as spurious, the position of the train is not updated.
If it wasn't really a spurious hit, then it's unlikely that the next sensor the train hits
will be attributed to it, because the model believes the train to be frozen at an old position.
This can cause all of the sensor hits of a train to be rejected as spurious, when a more sophisticated
model would realize that so many spurious hits is unlikely, and there is probably a real train
causing all of these hits.

\subsection{Following routes}
To drive a train down a route calculated by the routing server, we spawn a ``conductor'' task for each train.
This task operates as a server, so its steady state is to be receive blocked, waiting for timeouts, or notifications from other tasks.
The conductor's clients are the command server, which sends it destinations to route to; the train server, which
sends it information about sensor hits attributed to the conductor's train; and time outs initiated by the conductor itself.

It is notified by the command server that it should route that train to a particular position.
It then asks the routing server for a route, and begins to follow it.
As the train goes over the route, there are a series of positions of interest (POI) that the conductor needs to take
action at.
In our current implementation, there are points at which we want to switch a turnout, and one point where we want
to stop the train at the end of the route.
In the future, this approach could have been generalized to support reversing at a certain point, or stopping the train
before the end of the reserved segment of track.

The conductor calculates the next POI for each type of POI, and then selects the one which comes earliest in the route.
Note that the switch POI occur some distance before the train hits the switch, and the stopping POI occurs in advance of
the actual end of the route.
The POI is represented as the last sensor hit before the train should hit that POI, plus a delay in ticks.
As we pass that sensor, we spawn a task to wake the conductor after that delay by sending a request to the conductor.
When the request comes in, the conductor responds to the POI by stopping, or switching the switch,
then calculates the next POI.
If the next POI is offset from the same sensor as previously, the timeout begins immediately.
Otherwise, the conductor blocks until the right sensor is hit.

Whenever the conductor is notified of a sensor hit, it verifies that the train is on the desired path, and stops
the train if this is not the case.
In the future, we might have done more robust recovery from such error conditions, such as plotting a new route towards
the destination.

While the conductor will avoid currently reserved sections of track when planning routes, and reserves the track
that it needs, it doesn't currently handle stopping if it can't reserve the track neccesary.
The POI system could be augmented to implement this - a POI could be created the length of the stopping distance before the
end of the track reservation, at which point the conductor either needs to reserve more track, or stop the train.

We also don't handle paths which require reversing during the middle of the path.
This is because we could not get short moves to work reliably, and almost all reversing paths also involve short moves.

\subsection{Acceleration Model}
We made some more progress on our acceleration model from the state that we wrote about in the previous report.
We had gathered time-series data about the position of the train, and were able to fit a 5th-order polynomial to
the data.
Normally, you'd fit the polynomial to minimize squared errors, but we also restricted the polynomial by clamping
the derivatives at the extrema to zero.
Because the train has zero acceleration at the start and end of
the time period, a clamped curve is a more accurate model of reality.
We noticed that this curve fits relatively well to velocity data
when stopping from any speed, after scaling the curve in the x
and y axes.
This allows to generalize a single curve to any train running
at any speed, as long as we know the initial velocity, and
either the stopping time or stopping distance.

Because of this generalization, we were able to use the model
to calculate the position of the train while it was stopping.
We integrated under the curve for the time period we were interested
in to determine the distance travelled.
(Because the model is a polynomial, there is a closed-form solution
for the integral.)

This allows for better predicting the position of the train
while it stops.
It also simplifies the sensor attribution code, since it allows
us to take a calculation from the distance domain, and do it in
the time domain instead, which turns out to be much simpler to do.

We never generalized the model to work for accelerating from any
speed to any other speed, however.
The model that we had only worked for coming to a full stop.
To scale it, it's necessary to know how long the acceleration takes,
which can be approximated if the distance travelled is known.
Therefore, by knowing the stopping distance, we can scale a curve
to model velocity as the train stops.
However, we didn't have enough data to scale the model in other
situations.
If we wanted to generalize this in the future, we would need to collect the acceleration time for these speed transitions.
One way to collect this data would be to change the speed of
the train just as it passes a sensor, and then record
the distance travelled and time taken to get to the next sensor.
Because we know that the velocity is modelled by the polynomial while
the train is accelerating, and then by a constant after it's done,
we can set up an expression for the distance travelled by the train.
By setting this to be equal to the distance between the sensors, and the solving for the time taken to accelerate, we can get the necessary data.

% TODO: this is not super interesting - we could cut this if the whole thing gets too long
\subsection{Asynchronous sends and timing}
While writing the various servers, we found that a commonly used pattern was to want to have a request sent from a task
to itself after a delay.
We augmented the clock server to have a \texttt{delay\_async} command.
We wrote a simple implementation which leverages being able to destroy tasks and reuse their resources.
Normally, the clock server keeps waiting tasks reply-blocked, and replies to tasks which need to be woken up.
Instead, it replies immediately, then creates a one-use courier to pass the message to the task to be signalled.
The courier simply exits after sending the message, and its resources are recycled.
This approach doesn't scale particularly well, since each task requires a large stack, and one of a fairly limited number of task descriptors.
If we ran out of resources, we would need to use a solution with a fixed-size pool of workers, instead of
creating a new courier for each message.
However, this approach was much simpler to build, and we didn't encounter any scaling issues for what we were
using it for.


\end{document}
